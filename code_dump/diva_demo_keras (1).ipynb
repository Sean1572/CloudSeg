{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VsEzSnPkatxu"
   },
   "source": [
    "https://divamgupta.com/image-segmentation/2019/06/06/deep-learning-semantic-segmentation-keras.html Refer to this for reasource\n",
    "\n",
    "\n",
    "TODO: Add optimisers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L-e20af3aptg",
    "outputId": "2d82f2e4-9ab5-4f1c-eb6e-181cfd00130a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras-segmentation\n",
      "  Downloading keras_segmentation-0.3.0.tar.gz (23 kB)\n",
      "Collecting Keras>=2.0.0\n",
      "  Downloading keras-2.6.0-py2.py3-none-any.whl (1.3 MB)\n",
      "Collecting imageio==2.5.0\n",
      "  Downloading imageio-2.5.0-py3-none-any.whl (3.3 MB)\n",
      "Collecting imgaug==0.2.9\n",
      "  Downloading imgaug-0.2.9-py2.py3-none-any.whl (753 kB)\n",
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.5.4.58-cp38-cp38-win_amd64.whl (35.1 MB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\seanh\\anaconda3\\lib\\site-packages (from keras-segmentation) (4.59.0)\n",
      "Requirement already satisfied: pillow in c:\\users\\seanh\\anaconda3\\lib\\site-packages (from imageio==2.5.0->keras-segmentation) (8.2.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\seanh\\anaconda3\\lib\\site-packages (from imageio==2.5.0->keras-segmentation) (1.20.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\seanh\\anaconda3\\lib\\site-packages (from imgaug==0.2.9->keras-segmentation) (1.6.2)\n",
      "Requirement already satisfied: six in c:\\users\\seanh\\anaconda3\\lib\\site-packages (from imgaug==0.2.9->keras-segmentation) (1.15.0)\n",
      "Collecting Shapely\n",
      "  Downloading Shapely-1.7.1-cp38-cp38-win_amd64.whl (1.0 MB)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\seanh\\anaconda3\\lib\\site-packages (from imgaug==0.2.9->keras-segmentation) (3.3.4)\n",
      "Requirement already satisfied: scikit-image>=0.11.0 in c:\\users\\seanh\\anaconda3\\lib\\site-packages (from imgaug==0.2.9->keras-segmentation) (0.18.1)\n",
      "Requirement already satisfied: networkx>=2.0 in c:\\users\\seanh\\anaconda3\\lib\\site-packages (from scikit-image>=0.11.0->imgaug==0.2.9->keras-segmentation) (2.5)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in c:\\users\\seanh\\anaconda3\\lib\\site-packages (from scikit-image>=0.11.0->imgaug==0.2.9->keras-segmentation) (2021.4.8)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in c:\\users\\seanh\\anaconda3\\lib\\site-packages (from scikit-image>=0.11.0->imgaug==0.2.9->keras-segmentation) (1.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\seanh\\anaconda3\\lib\\site-packages (from matplotlib->imgaug==0.2.9->keras-segmentation) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\seanh\\anaconda3\\lib\\site-packages (from matplotlib->imgaug==0.2.9->keras-segmentation) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\seanh\\anaconda3\\lib\\site-packages (from matplotlib->imgaug==0.2.9->keras-segmentation) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\seanh\\anaconda3\\lib\\site-packages (from matplotlib->imgaug==0.2.9->keras-segmentation) (1.3.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\seanh\\anaconda3\\lib\\site-packages (from networkx>=2.0->scikit-image>=0.11.0->imgaug==0.2.9->keras-segmentation) (5.0.6)\n",
      "Building wheels for collected packages: keras-segmentation\n",
      "  Building wheel for keras-segmentation (setup.py): started\n",
      "  Building wheel for keras-segmentation (setup.py): finished with status 'done'\n",
      "  Created wheel for keras-segmentation: filename=keras_segmentation-0.3.0-py3-none-any.whl size=29071 sha256=4d0f9d45f81a55d1baed9d20b1d3b589eefd1971e0183dc5132fa2f1a429fba3\n",
      "  Stored in directory: c:\\users\\seanh\\appdata\\local\\pip\\cache\\wheels\\8f\\86\\73\\3dc66376905add0f57142bdd6e2117db5d4aa6340e34d039c7\n",
      "Successfully built keras-segmentation\n",
      "Installing collected packages: imageio, Shapely, opencv-python, Keras, imgaug, keras-segmentation\n",
      "  Attempting uninstall: imageio\n",
      "    Found existing installation: imageio 2.9.0\n",
      "    Uninstalling imageio-2.9.0:\n",
      "      Successfully uninstalled imageio-2.9.0\n",
      "Successfully installed Keras-2.6.0 Shapely-1.7.1 imageio-2.5.0 imgaug-0.2.9 keras-segmentation-0.3.0 opencv-python-4.5.4.58\n"
     ]
    }
   ],
   "source": [
    "!pip install keras-segmentation\n",
    "#https://github.com/divamgupta/image-segmentation-keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 231
    },
    "id": "Vw6J_5R8fax2",
    "outputId": "f475d9ae-dab8-46e6-a294-6a591142c3e1"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-87b9c413dd7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mnew_filename\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".png\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrgb_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mold_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrgb_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/test_images'"
     ]
    }
   ],
   "source": [
    "#make rgb images and segmentation images share a file name\n",
    "#get image in the right format\n",
    "\n",
    "import os\n",
    "from numpy import asarray\n",
    "from PIL import Image\n",
    "\n",
    "rgb_img = r'/home/test_images'\n",
    "seg_img = r'/home/test_segmentation/'\n",
    "rename = \"test_\"\n",
    "i = 0\n",
    "\n",
    "def remove_chars(filename):\n",
    "  new_filename = \"\"\n",
    "  for i in range(0, len(filename)):\n",
    "    char = filename[i]\n",
    "    if char.isnumeric():\n",
    "      new_filename += char\n",
    "  return new_filename + \".png\"\n",
    "\n",
    "for filename in os.listdir(rgb_img):\n",
    "    old_path = os.path.join(rgb_img, filename)\n",
    "    if not os.path.isdir(old_path):\n",
    "      i += 1\n",
    "      new_filename = remove_chars(filename)\n",
    "      os.rename(os.path.join(rgb_img, filename), os.path.join(rgb_img, new_filename))\n",
    "\n",
    "i = 0\n",
    "for filename in os.listdir(seg_img):\n",
    "    old_path = os.path.join(seg_img, filename)\n",
    "    if not os.path.isdir(old_path):\n",
    "      i += 1\n",
    "      new_filename = remove_chars(filename)\n",
    "      new_name = os.path.join(seg_img,new_filename)\n",
    "      os.rename(os.path.join(seg_img, filename), os.path.join(seg_img, new_name))\n",
    "      \n",
    "      \n",
    "      #Normalize image to fit model system: https://machinelearningmastery.com/how-to-manually-scale-image-pixel-data-for-deep-learning/ \n",
    "      image = Image.open(new_name)\n",
    "      pixels = asarray(image)\n",
    "      # convert from integers to floats\n",
    "      pixels = pixels.astype('float32')\n",
    "      # normalize to the range 0-1 then to 9\n",
    "      pixels /= 255.0\n",
    "      pixels *= 9.0\n",
    "      print('Min: %.3f, Max: %.3f' % (pixels.min(), pixels.max()))\n",
    "      im = Image.fromarray(pixels.astype(np.uint8))\n",
    "      im.save() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NTXCC6XffFn1",
    "outputId": "721b7a0c-69db-4ba5-c025-bf8091f4cab0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/keras_segmentation/__main__.py\", line 7, in <module>\n",
      "    main()\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/keras_segmentation/__main__.py\", line 4, in main\n",
      "    cli_interface.main()\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/keras_segmentation/cli_interface.py\", line 142, in main\n",
      "    args.func(args)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/keras_segmentation/cli_interface.py\", line 105, in action\n",
      "    args.images_path, args.segs_path, args.n_classes)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/keras_segmentation/data_utils/data_loader.py\", line 150, in verify_segmentation_dataset\n",
      "    img_seg_pairs = get_pairs_from_paths(images_path, segs_path)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/keras_segmentation/data_utils/data_loader.py\", line 42, in get_pairs_from_paths\n",
      "    for dir_entry in os.listdir(images_path):\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/home/test_images'\n"
     ]
    }
   ],
   "source": [
    "!python -m keras_segmentation verify_dataset \\\n",
    " --images_path=\"/home/test_images\" \\\n",
    " --segs_path=\"/home/test_segmentation/\"  \\\n",
    " --n_classes=10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_pyBnKNt_XJp"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 333
    },
    "id": "JjhHj2TcblZB",
    "outputId": "71b17783-3810-4cd1-963b-2b6316b3f65f"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "errorDetails": {
      "actions": [
       {
        "action": "open_url",
        "actionText": "Open Examples",
        "url": "/notebooks/snippets/importing_libraries.ipynb"
       }
      ]
     },
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-a8921c9ab139>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras_segmentation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras_segmentation'",
      "",
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from keras_segmentation import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e6vefJRV_Zko"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rrZ0uJsCbSpo"
   },
   "source": [
    "Create numpy dataset for data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 367
    },
    "id": "8F5MS0BLbAxX",
    "outputId": "30ccd57b-8819-4830-a72d-e735f8a1fb74"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "errorDetails": {
      "actions": [
       {
        "action": "open_url",
        "actionText": "Open Examples",
        "url": "/notebooks/snippets/importing_libraries.ipynb"
       }
      ]
     },
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-be31c8546e48>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras_segmentation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_segmentation_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras_segmentation'",
      "",
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model, model_from_json\n",
    "from keras.layers import Input, Dense, Conv2D, Dropout, MaxPooling2D, concatenate, UpSampling2D\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import keras\n",
    "from tensorflow import keras\n",
    "n_classes = 10\n",
    "input_height = 1080\n",
    "input_width = 720\n",
    "img_input = Input(shape=(input_height,input_width , 3 ))\n",
    "\n",
    "conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(img_input)\n",
    "conv1 = Dropout(0.2)(conv1)\n",
    "conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
    "pool1 = MaxPooling2D((2, 2))(conv1)\n",
    "\n",
    "conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
    "conv2 = Dropout(0.2)(conv2)\n",
    "conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
    "pool2 = MaxPooling2D((2, 2))(conv2)\n",
    "\n",
    "conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
    "conv3 = Dropout(0.2)(conv3)\n",
    "conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
    "\n",
    "up1 = concatenate([UpSampling2D((2, 2))(conv3), conv2], axis=-1)\n",
    "conv4 = Conv2D(64, (3, 3), activation='relu', padding='same')(up1)\n",
    "conv4 = Dropout(0.2)(conv4)\n",
    "conv4 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv4)\n",
    "\n",
    "up2 = concatenate([UpSampling2D((2, 2))(conv4), conv1], axis=-1)\n",
    "conv5 = Conv2D(32, (3, 3), activation='relu', padding='same')(up2)\n",
    "conv5 = Dropout(0.2)(conv5)\n",
    "conv5 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv5)\n",
    "\n",
    "out = Conv2D( n_classes, (1, 1) , padding='same')(conv5)\n",
    "\n",
    "from keras_segmentation.models.model_utils import get_segmentation_model\n",
    "\n",
    "\n",
    "model = get_segmentation_model(img_input ,  out,) # this would build the segmentation model\n",
    "opt = keras.optimizers.Relu(learning_rate=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "883msVaM-WI0"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "al0bAJwNegBj",
    "outputId": "4b000683-a13f-4e31-bbba-f74c5c4fde95"
   },
   "outputs": [
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying training dataset\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:01<00:00, 34.27it/s]\n",
      "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset verified! \n",
      "Epoch 1/5\n",
      "371/512 [====================>.........] - ETA: 1:24:48 - loss: 3.9610 - accuracy: 0.3736"
     ]
    }
   ],
   "source": [
    "model.train( \n",
    "    train_images =  \"/home/test_images/\",\n",
    "    train_annotations = \"/home/test_segmentation/\",\n",
    "    checkpoints_path = \"/home/weights/\" , epochs=5\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "diva_demo_keras.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
